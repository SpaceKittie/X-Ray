{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dental X-Ray Quadrant Detection\n",
    "\n",
    "This notebook demonstrates quadrant detection in dental X-rays using Detectron2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from src.models.config import get_quadrant_config\n",
    "from src.training.training import DentalTrainer, train_quadrant_phase\n",
    "from src.utils.visualization import DentalVisualizer, analyze_results\n",
    "from src.utils.config import load_paths\n",
    "from src.data.dataset import DentalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths from config\n",
    "paths = load_paths()\n",
    "\n",
    "# Get dataset paths\n",
    "train_img_dir = paths[\"data\"][\"images\"][\"train\"]\n",
    "val_img_dir = paths[\"data\"][\"images\"][\"val\"]\n",
    "train_json = paths[\"data\"][\"annotations\"][\"train\"]\n",
    "val_json = paths[\"data\"][\"annotations\"][\"val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and register training dataset\n",
    "train_dataset = DentalDataset(data_dir=train_img_dir, json_file=train_json)\n",
    "DatasetCatalog.register(\"quadrant_train\", train_dataset.get_dataset_dicts)\n",
    "MetadataCatalog.get(\"quadrant_train\").set(thing_classes=train_dataset.get_class_names())\n",
    "\n",
    "# Create and register validation dataset\n",
    "val_dataset = DentalDataset(data_dir=val_img_dir, json_file=val_json)\n",
    "DatasetCatalog.register(\"quadrant_val\", val_dataset.get_dataset_dicts)\n",
    "MetadataCatalog.get(\"quadrant_val\").set(thing_classes=val_dataset.get_class_names())\n",
    "\n",
    "# Get metadata for visualization\n",
    "metadata = MetadataCatalog.get(\"quadrant_train\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "visualizer = DentalVisualizer()\n",
    "\n",
    "# Get training data\n",
    "train_data = train_dataset.get_dataset_dicts()\n",
    "\n",
    "# Visualize a few samples\n",
    "for i, d in enumerate(train_data[:3]):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    visualizer.visualize_data_dict(img, d, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model configuration\n",
    "cfg = get_quadrant_config()\n",
    "\n",
    "# Display configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Base LR: {cfg.SOLVER.BASE_LR}\")\n",
    "print(f\"Max Iterations: {cfg.SOLVER.MAX_ITER}\")\n",
    "print(f\"Batch Size: {cfg.SOLVER.IMS_PER_BATCH}\")\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"Backbone: {cfg.MODEL.BACKBONE.NAME}\")\n",
    "print(f\"Number of Classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "weights_path = train_quadrant_phase(\n",
    "    data_dir=train_img_dir,\n",
    "    json_file=train_json,\n",
    "    output_dir=paths[\"models\"][\"quadrant\"][\"output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model for inference\n",
    "cfg.MODEL.WEIGHTS = weights_path\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Get validation data\n",
    "val_data = val_dataset.get_dataset_dicts()\n",
    "\n",
    "# Run inference on a few validation samples\n",
    "for d in val_data[:3]:\n",
    "    # Read image\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    # Visualize results\n",
    "    v = Visualizer(img, metadata=metadata)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(v.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze and print results\n",
    "    analyze_results(outputs, metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
